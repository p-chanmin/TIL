> 출처 : https://wikidocs.net/32012



# 2. 머신 러닝 훑어보기



## 2.1. 머신 러닝 모델의 평가

![img](https://wikidocs.net/images/page/24987/%EB%8D%B0%EC%9D%B4%ED%84%B0.PNG)

머신 러닝을 위한 데이터를 준비했다면 기계를 학습하기 전 해당 데이터를 훈련용, 검증용, 테스트용 이렇게 세 가지로 분리하는 것이 일반적

* **훈련 데이터**

  머신 러닝 모델을 학습하는 용도

* **테스트 데이터**

  학습한 머신 러닝 모델의 성능을 평가하기 위한 용도

* **검증용 데이터**

  모델의 성능을 조정하기 위한 용도

  정확히는 모델이 훈련 데이터에 **과적합(overfitting)** 이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도

  * **하이퍼파라미터(초매개변수)** : 모델의 성능에 영향을 주는 사람이 값을 지정하는 변수.
  * **매개변수** : 가중치와 편향. 학습을 하는 동안 값이 계속해서 변하는 수.

  훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 **튜닝(tuning)** 한다.  검증용 데이터에 대해서 높은 정확도를 얻도록 하이퍼파라미터의 값을 바꿔보는 것



## 2.**2. 분류(Classification)와 회귀(Regression)**

머신 러닝의 많은 문제는 분류 또는 회귀 문제에 속한다.

선형 회귀는 대표적인 회귀 문제에 속하고, 로지스틱 회귀는 (이름은 회귀이지만) 대표적인 분류 문제에 속한다.

분류는 또한 이진 분류(Binary Classification)과 다중 클래스 분류(Multi-Class Classification)로 나뉜다.



* **이진 분류 문제(Binary Classification)**

  이진 분류는 주어진 입력에 대해서 두 개의 선택지 중 하나의 답을 선택해야 하는 경우

* **다중 클래스 분류(Multi-class Classification)**

  다중 클래스 분류는 주어진 입력에 대해서 세 개 이상의 선택지 중에서 답을 선택해야 하는 경우

* **회귀 문제(Regression)**

  어떠한 연속적인 값의 범위 내에서 예측값이 나오는 경우



## 2.3. 지도 학습과 비지도 학습

머신 러닝은 크게 지도 학습, 비지도 학습, 강화 학습으로 나뉜다.

큰 갈래로서는 자주 언급 되지는 않지만 딥 러닝 자연어 처리에서 중요한 학습 방법 중 하나인 자기지도 학습(Self-Supervised Learning, SSL)이 있다.



* **지도 학습(Supervised Learning)**

  지도 학습이란 레이블(Label)이라는 정답과 함께 학습하는 것

* **비지도 학습(Unsupervised Learning)**

  비지도 학습은 데이터에 별도의 레이블이 없이 학습하는 것

* **자기지도 학습(Self-Supervised Learning, SSL)**

  레이블이 없는 데이터가 주어지면, 모델이 학습을 위해서 스스로 데이터로부터 레이블을 만들어서 학습하는 경우



## 2.4. 샘플(Sample)과 특성(Feature)

많은 머신 러닝 문제가 1개 이상의 독립 변수 x를 가지고 종속 변수 y를 예측하는 문제이다.

머신 러닝 모델 중 특히 인공 신경망은 독립 변수, 종속 변수, 가중치, 편향 등을 행렬 연산을 통해 연산하는 경우가 많다.

인공 신경망을 배우게되면 훈련 데이터를 행렬로 표현하는 경우를 많이 보게 된다.

독립 변수 x의 행렬을 X라고 하였을 때, 독립 변수의 개수가 n개이고 데이터의 개수가 m인 행렬 X는 다음과 같다.

![img](https://wikidocs.net/images/page/35821/n_x_m.PNG)

이때 머신 러닝에서는 하나의 데이터. 행렬 관점에서는 하나의 행을 샘플(Sample)이라고 부른다.

종속 변수 y를 예측하기 위한 각각의 독립 변수 x를 특성(Feature)이라고 부른다. 행렬 관점에서는 각 열



## 2.5. 혼동 행렬(Confusion Matrix)

머신 러닝에서는 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)라고 한다.

정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지는 않는다.

이를 위해서 사용하는 것이 혼동 행렬(Confusion Matrix)이다.

예를 들어 참(True)와 거짓(False) 둘 중 하나를 예측하는 문제였다고 가정해보자.

아래의 혼동 행렬에서 각 열은 예측값을 나타내며, 각 행은 실제값을 나타낸다.

| -         | 예측 참 | 예측 거짓 |
| :-------- | :------ | :-------- |
| 실제 참   | TP      | FN        |
| 실제 거짓 | FP      | TN        |

머신 러닝에서는 다음과 같은 네 가지 케이스에 대해서 각각 TP, FP, FN, TN을 정의

- **True Positive(TP)** : 실제 True인 정답을 True라고 예측 (정답)
- **False Positive(FP)** : 실제 False인 정답을 True라고 예측 (오답)
- **False Negative(FN)** : 실제 True인 정답을 False라고 예측 (오답)
- **True Negative(TN)** : 실제 False인 정답을 False라고 예측 (정답)

---

이 개념을 사용하면 정밀도(Precision)과 재현율(Recall)을 얻을 수 있다.

* **정밀도(Precision)**

  모델이 True라고 분류한 것 중에서 실제 True인 것의 비율

  <img src="https://latex.codecogs.com/svg.image?Precision&space;=&space;\frac{TP}{TP&space;&plus;&space;FP}" title="Precision = \frac{TP}{TP + FP}" />

* **재현율(Recall)**

  실제 True인 것 중에서 모델이 True라고 예측한 것의 비율

  <img src="https://latex.codecogs.com/svg.image?Recall&space;=&space;\frac{TP}{TP&space;&plus;&space;FN}" title="Recall = \frac{TP}{TP + FN}" />

* **정확도(Accuracy)**

  전체 예측한 데이터 중에서 정답을 맞춘 것에 대한 비율

  <img src="https://latex.codecogs.com/svg.image?Accuracy&space;=&space;\frac{TP&plus;TN}{TP&space;&plus;&space;FN&plus;FP&plus;TN}" title="Accuracy = \frac{TP+TN}{TP + FN+FP+TN}" />

   Accuracy로 성능을 예측하는 것이 적절하지 않은 때가 있다.



## 2.**6. 과적합(Overfitting)과 과소 적합(Underfitting)**

머신 러닝에서 **과적합(Overfitting)** 이란 훈련 데이터를 과하게 학습한 경우를 말한다.

머신 러닝 모델이 학습에 사용하는 훈련 데이터는 실제로 앞으로 기계가 풀어야 할 현실의 수많은 문제에 비하면 극히 일부에 불과한 데이터

기계가 훈련 데이터에 대해서만 과하게 학습하면 성능 측정을 위한 데이터인 테스트 데이터나 실제 서비스에서는 정확도가 좋지 않은 현상이 발생

과적합 상황에서는 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 커진다.

아래의 그래프는 과적합 상황에서 발생할 수 있는 훈련 데이터에 대한 훈련 횟수에 따른 훈련 데이터의 오차와 테스트 데이터의 오차(또는 손실)의 변화

![img](https://wikidocs.net/images/page/32012/%EC%8A%A4%ED%8C%B8_%EB%A9%94%EC%9D%BC_%EC%98%A4%EC%B0%A8.png)

RNN을 이용한 텍스트 분류 챕터의 스팸 메일 분류하기 실습에서 훈련 데이터에 대한 훈련 횟수를 30 에포크로 주어서 의도적으로 과적합을 발생시킨 그래프

y축은 오차(loss), X축의 에포크(epoch)는 전체 훈련 데이터에 대한 훈련 횟수를 의미

과적합은 훈련 데이터에 대한 정확도는 높지만, 테스트 데이터는 정확도가 낮은 상황

이런 상황을 방지하기 위해서는 테스트 데이터의 오차가 증가하기 전이나, 정확도가 감소하기 전에 훈련을 멈추는 것이 바람직하다.

---

테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태를 **과소적합(Underfitting)** 이라고 한다.

과소 적합은 훈련 자체가 부족한 상태이므로 훈련 횟수인 에포크가 지나치게 적으면 발생할 수 있다.

과대 적합과는 달리 과소 적합은 훈련 자체를 너무 적게한 상태이므로 훈련 데이터에 대해서도 정확도가 낮다는 특징

두 가지 현상을 과적합과 과소 적합이라고 부르는 이유는 머신 러닝에서 학습 또는 훈련이라고 하는 과정을 적합(fitting)이라고도 부르기 때문이다. 모델이 주어진 데이터에 대해서 적합해져가는 과정이기 때문이다.

이러한 이유로 케라스에서는 기계를 학습시킬 때 fit()을 호출

---

과적합 방지를 고려한 일반적인 딥 러닝 모델의 학습 과정

- Step 1. 주어진 데이터를 훈련 데이터, 검증 데이터, 테스트 데이터로 나눈다. 가령, 6:2:2 비율로 나눌 수 있다.
- Step 2. 훈련 데이터로 모델을 학습한다. (에포크 +1)
- Step 3. 검증 데이터로 모델을 평가하여 검증 데이터에 대한 정확도와 오차(loss)를 계산한다.
- Step 4. 검증 데이터의 오차가 증가하였다면 과적합 징후이므로 학습 종료 후 Step 5로 이동, 아니라면 Step 2.로 재이동한다.
- Step 5. 모델의 학습이 종료되었으니 테스트 데이터로 모델을 평가한다.