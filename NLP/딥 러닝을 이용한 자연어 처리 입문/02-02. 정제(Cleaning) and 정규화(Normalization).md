> 출처 : https://wikidocs.net/21693



# 2. 정제(Cleaning) and 정규화(Normalization)

- 정제(cleaning) : 갖고 있는 코퍼스로부터 노이즈 데이터를 제거.
- 정규화(normalization) : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만든다.

정제 작업은 토큰화 작업에 방해가 되는 부분들을 배제시키고 토큰화 작업을 수행하기 위해서 토큰화 작업보다 앞서 이루어지기도 하지만, 토큰화 작업 이후에도 여전히 남아있는 노이즈들을 제거하기위해 지속적으로 이루어진다.

완벽한 정제 작업은 어려운 편이라서, 대부분의 경우 이 정도면 됐다.라는 일종의 합의점을 찾기도 한다.



## 2.1. 규칙에 기반한 표기가 다른 단어들의 통합

필요에 따라 직접 코딩을 통해 정의할 수 있는 정규화 규칙의 예로서 같은 의미를 갖고있음에도, 표기가 다른 단어들을 하나의 단어로 정규화하는 방법을 사용할 수 있다.

* USA와 US는 같은 의미를 가지므로 하나의 단어로 정규화
* uh-huh와 uhhuh 처럼 형태는 다르지만 같은 의미를 가지므로 하나의 단어로 정규화

표기가 다른 단어들을 통합하는 방법은 **어간 추출(stemming)**과 **표제어 추출(lemmatizaiton)**이 있다.



## 2.2. 대, 소문자 통합

영어에서는 대, 소문자를 통합하는 것이 단어의 개수를 줄일 수 있는 또 다른 정규화 방법이다.

영어에서의 대문자는 문장의 맨 앞과 같은 특정한 상황에서만 쓰이고, 대부분은 소문자로 작성되기 때문에 대, 소문자 통합 작업은 대부분 대문자를 소문자로 변환한다.

소문자 변환을 사용하면 소문자의 질의 결과로서 대문자를 포함한 단어를 찾을 수 있다.

하지만 무작정 대, 소문자를 통합해서는 안된다. US와 us같은 것들은 구분되어야 한다.

따라서 어떤 것을 대문자로 두고, 소문자로 변환할 것인지 결정해야한다. 이 때 머신 러닝 시퀸스 모델로 더 정확하게 진행 할 수 있다.



## 2.3. 불필요한 단어의 제거

정제 작업에서 제거해야하는 노이즈는 자연어가 아니면서 아무 의미도 갖지 않은 글자들을 의미하며, 분석하고자 하는 목적에 맞지 않는 불필요한 단어들을 포함한다.

불필요한 단어들을 제거하는 방법

* 등장빈도가 적은 단어

  너무 적게 등장해서 자연어 처리에 도움이 되지 않는 단어들이 존재한다.

* 길이가 짧은 단어

  길이가 짧은 단어를 삭제하는 것만으로도 자연어 처리에서 크게 의미가 없는 단어들을 제거하는 효과를 볼 수 있다. 즉, 영어권 언어에서는 길이가 짧은 단어들은 대부분 불용어에 해당된다.

  이러한 특성으로 인해 영어는 길이가 2~3 이하인 단어를 제거하는 것만으로 크게 의미를 갖지 못하는 단어를 줄이는 효과를 가지고 있다.

  ```python
  import re
  text = "I was wondering if anyone out there could enlighten me on this car."
  
  # 길이가 1~2인 단어들을 정규 표현식을 이용하여 삭제
  shortword = re.compile(r'\W*\b\w{1,2}\b')
  print(shortword.sub('', text))
  ```

  * 결과

  ```
  was wondering anyone out there could enlighten this car.
  ```

  

## 2.4 정규 표현식

노이즈 데이터의 특징을 알면, 정규 표현식을 통해서 이를 제거할 수 있는 경우가 많다.