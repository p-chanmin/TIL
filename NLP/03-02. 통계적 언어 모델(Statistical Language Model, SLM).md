> 출처 : https://wikidocs.net/21687



# 2. 통계적 언어 모델(Statistical Language Model, SLM)

언어 모델의 전통적인 접근 방법인 통계적 언어 모델

통계적 언어 모델(Statistical Language Model)은 줄여서 SLM



## 2.1. 조건부 확률

조건부 확률은 두 확률 P(A),P(B)에 대해서 아래와 같은 관계
$$
P(B|A) = P(A,B)/P(A)
$$

$$
P(A,B) = P(A)P(B|A)
$$

4개의 확률이 조건부 확률의 관계
$$
P(A,B,C,D) = P(A)P(B|A)P(C|A,B)P(D|A,B,C)
$$
조건부 확률의 연쇄 법칙(chain rule)
$$
P(x_1, x_2, x_3 ... x_n) = P(x_1)P(x_2|x_1)P(x_3|x_1,x_2)...P(x_n|x_1 ... x_{n-1})
$$


## 2.2. **문장에 대한 확률**

문장 'An adorable little boy is spreading smiles'의 확률 **P(An adorable little boy is spreading smiles)**를 식으로 표현

각 단어는 문맥이라는 관계로 인해 이전 단어의 영향을 받아 나온 단어이고, 모든 단어로부터 하나의 문장이 완성된다. 

위의 문장에 해당 식을 적용해보면 다음과 같다.
$$
P(\text{An adorable little boy is spreading smiles}) = P(\text{An})  ×  P(\text{adorable|An})  ×  P(\text{little|An adorable})  ×  P(\text{boy|An adorable little})
         ×  P(\text{is|An adorable little boy})
$$
문장의 확률을 구하기 위해서 각 단어에 대한 예측 확률들을 곱한다.



## 2.3. **카운트 기반의 접근**

SLM은 이전 단어로부터 다음 단어에 대한 확률을 카운트에 기반하여 계산한다.

An adorable little boy가 나왔을 때, is가 나올 확률인 P(is|An adorable little boy)를 구하면
$$
P\text{(is|An adorable little boy}) = \frac{\text{count(An adorable little boy is})}{\text{count(An adorable little boy })}
$$
기계가 학습한 코퍼스 데이터에서 An adorable little boy가 100번 등장했는데 그 다음에 is가 등장한 경우는 30번이라고 합시다. 이 경우 P(is|An adorable little boy)는 30%



## 2.4. **카운트 기반 접근의 한계 - 희소 문제(Sparsity Problem)**

언어 모델은 실생활에서 사용되는 언어의 확률 분포를 근사 모델링

정확하게 알아볼 방법은 없겠지만 현실에서도 An adorable little boy가 나왔을 때 is가 나올 확률이라는 것이 존재

기계에게 많은 코퍼스를 훈련시켜서 언어 모델을 통해 현실에서의 확률 분포를 근사하는 것이 언어 모델의 목표

카운트 기반으로 접근하려고 한다면 갖고있는 코퍼스(corpus). 즉, 다시 말해 기계가 훈련하는 데이터는 정말 방대한 양이 필요

위에서의 예로 기계가 훈련한 코퍼스에 An adorable little boy is라는 단어 시퀀스가 없었다면 이 단어 시퀀스에 대한 확률은 0이 된다.

또는 An adorable little boy라는 단어 시퀀스가 없었다면 분모가 0이 되어 확률은 정의되지 않는다.

코퍼스에 단어 시퀀스가 없다고 해서 이 확률을 0 또는 정의되지 않는 확률이라고 하는 것이 정확한 모델링 방법이 아니다.

충분한 데이터를 관측하지 못하여 언어를 정확히 모델링하지 못하는 문제를 **희소 문제(sparsity problem)**라고 한다.