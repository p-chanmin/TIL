> 출처 : https://wikidocs.net/22881



# 5. 로지스틱 회귀(Logistic Regression)

일상 속 풀고자하는 많은 문제 중에서는 두 개의 선택지 중에서 정답을 고르는 문제가 많다.

둘 중 하나를 결정하는 문제를 이진 분류(Binary Classification)라고 한다.

이런 문제를 풀기 위한 대표적인 알고리즘으로 로지스틱 회귀(Logistic Regression)



## 5.**1. 이진 분류(Binary Classification)**

학생들이 시험 성적에 따라서 합격, 불합격이 기재된 데이터가 있다고 가정

시험 성적이 x라면, 합불 결과는 y

이 데이터로부터 특정 점수를 얻었을 때의 합격, 불합격 여부를 판정하는 모델을 만들고자 한다.

| score(x) | result(y) |
| :------- | :-------- |
| 45       | 불합격    |
| 50       | 불합격    |
| 55       | 불합격    |
| 60       | 합격      |
| 65       | 합격      |
| 70       | 합격      |

위 데이터에서 합격을 1, 불합격을 0이라고 하였을 때 그래프를 그려보면 아래와 같다.

![img](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.PNG)

이러한 점들을 표현하는 그래프는 알파벳의 S자 형태로 표현된다.

이러한 x와 y의 관계를 표현하기 위해서는 직선을 표현하는 함수가 아니라 S자 형태로 표현할 수 있는 함수가 필요

레이블에 해당하는 y가 0 또는 1이라는 두 가지 값만을 가지므로, 이 문제를 풀기 위해서 예측값은 0과 1사이의 값을 가지도록 한다.

0과 1사이의 값을 확률로 해석하면 문제를 풀기가 훨씬 용이해진다.

최종 예측값이 0.5보다 작으면 0으로 예측했다고 판단하고, 0.5보다 크면 1로 예측했다고 판단

출력이 0과 1사이의 값을 가지면서 S자 형태로 그려지는 함수로 시그모이드 함수(Sigmoid function)



## 5.**2. 시그모이드 함수(Sigmoid function)**

시그모이드 함수는 종종 σ로 축약해서 표현하기도 한다.

로지스틱 회귀를 풀기 위한 가설

<img src="https://latex.codecogs.com/svg.image?H(x)&space;=&space;\frac{1}{1&space;&plus;&space;e^{-(wx&space;&plus;&space;b)}}&space;=&space;sigmoid(wx&space;&plus;&space;b)&space;=&space;\sigma&space;(wx&space;&plus;&space;b)" title="H(x) = \frac{1}{1 + e^{-(wx + b)}} = sigmoid(wx + b) = \sigma (wx + b)" />

여기서 e(e=2.718281...)는 자연 상수

구해야할 것은 여전히 주어진 데이터에 가장 적합한 가중치 w(weight)와 편향 b(bias)

인공 지능 알고리즘이 하는 것은 결국 주어진 데이터에 적합한 가중치 w와 b를 구하는 것이다.

시그모이드 함수를 그래프로 시각화

```python
import numpy as np
import matplotlib.pyplot as plt
```

아래의 그래프는 w는 1, b는 0임을 가정한 그래프

```python
def sigmoid(x):
    return 1/(1+np.exp(-x))

x = np.arange(-5.0, 5.0, 0.1)
y = sigmoid(x)

plt.plot(x, y, 'g')
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```

![img](https://wikidocs.net/images/page/22881/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%EA%B7%B8%EB%9E%98%ED%94%84.png)

위의 그래프에서 시그모이드 함수는 출력값을 0과 1사이의 값으로 조정하여 반환

S자의 모양을 연상

* w의 값을 변화시키고 이에 따른 그래프를 확인

```python
def sigmoid(x):
    return 1/(1+np.exp(-x))

x = np.arange(-5.0, 5.0, 0.1)
y1 = sigmoid(0.5*x)
y2 = sigmoid(x)
y3 = sigmoid(2*x)

plt.plot(x, y1, 'r', linestyle='--') # w의 값이 0.5일때
plt.plot(x, y2, 'g') # w의 값이 1일때
plt.plot(x, y3, 'b', linestyle='--') # w의 값이 2일때
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```

![img](https://wikidocs.net/images/page/22881/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C%ED%95%A8%EC%88%98%EC%9D%98%EA%B8%B0%EC%9A%B8%EA%B8%B0%EC%9D%98%EB%B3%80%ED%99%94.png)

위 그래프는 w의 값이 0.5일때 빨간색선, w의 값이 1일때는 초록색선, w의 값이 2일때 파란색선이 나오도록 하였다.

 w의 값이 커지면 경사가 커지고 w의 값이 작아지면 경사가 작아진다.



* b의 값에 따라서 그래프가 어떻게 변하는지 확인

```python
def sigmoid(x):
    return 1/(1+np.exp(-x))

x = np.arange(-5.0, 5.0, 0.1)
y1 = sigmoid(x+0.5)
y2 = sigmoid(x+1)
y3 = sigmoid(x+1.5)

plt.plot(x, y1, 'r', linestyle='--') # x + 0.5
plt.plot(x, y2, 'g') # x + 1
plt.plot(x, y3, 'b', linestyle='--') # x + 1.5
plt.plot([0,0],[1.0,0.0], ':') # 가운데 점선 추가
plt.title('Sigmoid Function')
plt.show()
```

![img](https://wikidocs.net/images/page/22881/b%EC%9D%98%EC%9D%B4%EB%8F%99.png)

위 그래프는 b값에 따라서 그래프가 이동하는 것을 보여준다.

시그모이드 함수는 입력값이 커지면 1에 수렴하고, 입력값이 작아지면 0에 수렴

0부터의 1까지의 값을 가지는데 출력값이 0.5 이상이면 1(True), 0.5이하면 0(False)로 만들면 이진 분류 문제를 풀기 위해서 사용할 수 있다.



## 5.**3. 비용 함수(Cost function)**

로지스틱 회귀 또한 경사 하강법을 사용하여 가중치 w를 찾아내지만, 비용 함수로는 평균 제곱 오차를 사용하지 않는다.

![img](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%801.JPG)

로지스틱 회귀에서 평균 제곱 오차를 비용 함수로 사용하면, 경사 하강법을 사용하였을때 찾고자 하는 최소값이 아닌 잘못된 최소값에 빠질 가능성이 매우 높다.

이를 전체 함수에 걸쳐 최소값인 **글로벌 미니멈(Global Minimum)** 이 아닌 특정 구역에서의 최소값인 **로컬 미니멈(Local Minimum)** 에 도달했다고 한다.

로컬 미니멈에 지나치게 쉽게 빠지는 비용 함수는 cost가 가능한한 최소가 되는 가중치 w를 찾는다는 목적에는 좋지 않은 선택

---

<img src="https://latex.codecogs.com/svg.image?J(w)&space;=&space;\frac{1}{n}&space;\sum_{i=1}^{n}&space;cost\left(H(x^{(i)}),&space;y^{(i)})\right)" title="J(w) = \frac{1}{n} \sum_{i=1}^{n} cost\left(H(x^{(i)}), y^{(i)})\right)" />

시그모이드 함수는 0과 1사이의 y값을 반환한다.

이는 실제값이 0일 때 y값이 1에 가까워지면 오차가 커지며 실제값이 1일 때 y값이 0에 가까워지면 오차가 커짐을 의미

이를 반영할 수 있는 함수는 로그 함수를 통해 표현 가능

<img src="https://latex.codecogs.com/svg.image?\text{if&space;}&space;y=1&space;\to&space;&space;\text{cost}\left(&space;H(x),&space;y&space;\right)&space;=&space;-\log(H(x))" title="\text{if } y=1 \to \text{cost}\left( H(x), y \right) = -\log(H(x))" />

<img src="https://latex.codecogs.com/svg.image?\text{if&space;}&space;y=0&space;\to&space;&space;\text{cost}\left(&space;H(x),&space;y&space;\right)&space;=&space;-\log(1-H(x))" title="\text{if } y=0 \to \text{cost}\left( H(x), y \right) = -\log(1-H(x))" />

y의 실제값이 1일 때 −logH(x) 그래프를 사용하고 y의 실제값이 0일 때 −log(1−H(x)) 그래프를 사용해야 한다.

위의 두 식을 그래프 상으로 표현하면 아래와 같다.

![img](https://wikidocs.net/images/page/22881/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%802.JPG)

실제값 y가 1일 때의 그래프를 파란색 선으로 표현하였으며, 실제값 y가 0일 때의 그래프를 빨간색 선으로 표현하였다.

이는 다음과 같이 하나의 식으로 표현할 수 있다.

<img src="https://latex.codecogs.com/svg.image?\text{cost}\left(&space;H(x),&space;y&space;\right)&space;=&space;-[ylogH(x)&space;&plus;&space;(1-y)log(1-H(x))]" title="\text{cost}\left( H(x), y \right) = -[ylogH(x) + (1-y)log(1-H(x))]" />

결과적으로 로지스틱 회귀의 목적 함수는 아래와 같다.

<img src="https://latex.codecogs.com/svg.image?J(w)&space;=&space;-\frac{1}{n}&space;\sum_{i=1}^{n}&space;[y^{(i)}logH(x^{(i)})&space;&plus;&space;(1-y^{(i)})log(1-H(x^{(i)}))]" title="J(w) = -\frac{1}{n} \sum_{i=1}^{n} [y^{(i)}logH(x^{(i)}) + (1-y^{(i)})log(1-H(x^{(i)}))]" />

로지스틱 회귀에서 찾아낸 비용 함수를 **크로스 엔트로피(Cross Entropy)함수**

결론적으로 로지스틱 회귀는 비용 함수로 **크로스 엔트로피 함수를 사용**하며, 가중치를 찾기 위해서 **크로스 엔트로피 함수의 평균을 취한 함수를 사용**